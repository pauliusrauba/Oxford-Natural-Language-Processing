{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formative 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from html import unescape\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk import sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to clean and split text\n",
    "def clean(text):\n",
    "    text = unescape(text)\n",
    "    return [re.sub('[^a-z0-9]', '', w.lower()) for w in text.strip().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "df = pd.read_csv('reddit_mbti.csv')\n",
    "\n",
    "# Remove columns not needed for formative\n",
    "df = df[['comment', 'type']]\n",
    "\n",
    "# Remove empty comments\n",
    "#df = df[df.comment.apply(lambda x: len(clean(x))) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you really want to go down this path?  Would y...</td>\n",
       "      <td>enfp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I think insurance companies do that.  Once you...</td>\n",
       "      <td>intp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I see it as 22,500 people working for about an...</td>\n",
       "      <td>intp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our President stands ready to ride his golf ca...</td>\n",
       "      <td>intp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some write that he was trying to say \"big leag...</td>\n",
       "      <td>intp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  type\n",
       "0  you really want to go down this path?  Would y...  enfp\n",
       "1  I think insurance companies do that.  Once you...  intp\n",
       "2  I see it as 22,500 people working for about an...  intp\n",
       "3  Our President stands ready to ride his golf ca...  intp\n",
       "4  Some write that he was trying to say \"big leag...  intp"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary for particle look-up\n",
    "p2id = {'over': 0, 'back': 1, 'around': 2, 'out': 3}\n",
    "\n",
    "# Define dictionary for reverse particle look-up\n",
    "id2p = {v: k for k, v in p2id.items()}\n",
    "\n",
    "# Initialize lists for storing contexts around particles\n",
    "sent_1 = list()\n",
    "sent_2 = list()\n",
    "\n",
    "# Initialize list for storing labels\n",
    "labels = list()\n",
    "\n",
    "# Loop over comments\n",
    "for c in df.comment:\n",
    "    \n",
    "    # Loop over individual sentences\n",
    "    for s in sent_tokenize(c):\n",
    "        \n",
    "        # Clean and split sentence\n",
    "        split = clean(s)\n",
    "        \n",
    "        if len(split) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Add sentence to list if only one particle in sentence\n",
    "        if len([w for w in split if w in p2id]) == 1:\n",
    "            \n",
    "            # Identify particle\n",
    "            p = [w for w in split if w in p2id][0]\n",
    "\n",
    "            # Store contexts and label\n",
    "            sent_1.append(split[:split.index(p)])\n",
    "            sent_2.append(split[split.index(p) + 1:])\n",
    "            labels.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with contexts and labels and perform stratified sampling\n",
    "p_df = pd.DataFrame({'sent_1': sent_1, 'sent_2': sent_2, 'label': labels})[['sent_1', 'sent_2', 'label']]\n",
    "p_df = p_df.groupby('label', group_keys=False).apply(lambda x: x.sample(n=1500, random_state=0)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe into training, evaluation, and test data\n",
    "train, dev_test = train_test_split(p_df, test_size=0.2, stratify=p_df['label'], random_state=0)\n",
    "dev, test = train_test_split(dev_test, test_size=0.5, stratify=dev_test['label'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for word look-up\n",
    "word_counter = Counter([w for s in train.sent_1 for w in s] + [w for s in train.sent_2 for w in s])\n",
    "w2id = {w: i + 2 for i, w in enumerate(w for w, c in word_counter.most_common())}\n",
    "\n",
    "# Create dictionary for reverse word look-up\n",
    "id2w = {i: w for w, i in w2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to encode sentences\n",
    "def encode(sent, w2id):\n",
    "    return [w2id[w] if w in w2id else 1 for w in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to pad sentences\n",
    "def pad(sent):\n",
    "    if len(sent) > 5:\n",
    "        sent = sent[-5:]\n",
    "    elif len(sent) < 5:\n",
    "        sent = [0] * (5 - len(sent)) + sent\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and pad sentences\n",
    "for data in [train, dev, test]:\n",
    "    \n",
    "    # Encode and pad left contexts\n",
    "    data['enc_1'] = data.sent_1.apply(lambda x: pad(encode(x, w2id)))\n",
    "    \n",
    "    # Reverse order of right contexts prior to padding\n",
    "    data['enc_2'] = data.sent_2.apply(lambda x: pad(encode(x, w2id)[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for classifier training and evaluation\n",
    "def train_classifier(classifier, train_x, train_y, dev_x, dev_y, test_x, test_y, device):\n",
    "    \n",
    "    # Define training objective\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=0.01)\n",
    "    \n",
    "    # Move model and data to CUDA\n",
    "    classifier = classifier.to(device)\n",
    "    [train_x, train_y, dev_x, dev_y, test_x, test_y] = [data.to(device) for data in [train_x, train_y, dev_x, dev_y, test_x, test_y]]\n",
    "    \n",
    "    # Train model\n",
    "    for epoch in range(1, 21):\n",
    "        \n",
    "        # Perform forward pass\n",
    "        classifier.train()\n",
    "        \n",
    "        optimizer.zero_grad() # <--- \n",
    "        output = classifier(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        \n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Evaluate model every fifth epoch\n",
    "        if epoch % 5 == 0:\n",
    "\n",
    "            classifier.eval() # <--- \"what i'm donna do next\"\n",
    "\n",
    "            with torch.no_grad():\n",
    "                    \n",
    "                    # Perform forward pass\n",
    "                    output =  classifier(dev_x)\n",
    "                    \n",
    "                    # Make prediction\n",
    "                    max_output = output.argmax(dim=1, keepdim=True)\n",
    "                    \n",
    "                    # Compute accuracy\n",
    "                    acc = max_output.squeeze(1).eq(dev_y).sum() / torch.FloatTensor([dev_y.shape[0]])\n",
    "\n",
    "                    print('Accuracy on dev data after {:02d} epochs: {:.4f}'.format(epoch, acc.data.item()))\n",
    "    \n",
    "    # Test model\n",
    "    classifier.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Perform forward pass\n",
    "        output =  classifier(test_x)\n",
    "        \n",
    "        # Make prediction\n",
    "        max_output = output.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        acc = max_output.squeeze(1).eq(test_y).sum() / torch.FloatTensor([test_y.shape[0]])\n",
    "        \n",
    "        print('Accuracy on test data: {:.4f}'.format(acc.data.item()))\n",
    "\n",
    "    # Return labels and predictions\n",
    "    return acc.data.item(), [l.item() for l in test_y], [p.item() for p in max_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part II: Logistic Regression Classifier\n",
    "\n",
    "# Define logistic regression classifier class\n",
    "class LRClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \n",
    "        super(LRClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert context into sparse indicator vector\n",
    "def sent2sparse(sent_1, sent_2, vocab):\n",
    "    counter = Counter(sent_1 + sent_2)\n",
    "    return [counter[w] for w in sorted(vocab)[:5000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "input_dim = 5000\n",
    "output_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using context window size of 1...\n",
      "Accuracy on dev data after 05 epochs: 0.5717\n",
      "Accuracy on dev data after 10 epochs: 0.5983\n",
      "Accuracy on dev data after 15 epochs: 0.5850\n",
      "Accuracy on dev data after 20 epochs: 0.5900\n",
      "Accuracy on test data: 0.5833\n",
      "Using context window size of 2...\n",
      "Accuracy on dev data after 05 epochs: 0.5233\n",
      "Accuracy on dev data after 10 epochs: 0.5350\n",
      "Accuracy on dev data after 15 epochs: 0.5417\n",
      "Accuracy on dev data after 20 epochs: 0.5533\n",
      "Accuracy on test data: 0.5500\n",
      "Using context window size of 3...\n",
      "Accuracy on dev data after 05 epochs: 0.5233\n",
      "Accuracy on dev data after 10 epochs: 0.5233\n",
      "Accuracy on dev data after 15 epochs: 0.5317\n",
      "Accuracy on dev data after 20 epochs: 0.5250\n",
      "Accuracy on test data: 0.5083\n",
      "Using context window size of 4...\n",
      "Accuracy on dev data after 05 epochs: 0.4750\n",
      "Accuracy on dev data after 10 epochs: 0.4850\n",
      "Accuracy on dev data after 15 epochs: 0.5017\n",
      "Accuracy on dev data after 20 epochs: 0.5067\n",
      "Accuracy on test data: 0.4900\n",
      "Using context window size of 5...\n",
      "Accuracy on dev data after 05 epochs: 0.4650\n",
      "Accuracy on dev data after 10 epochs: 0.4600\n",
      "Accuracy on dev data after 15 epochs: 0.4600\n",
      "Accuracy on dev data after 20 epochs: 0.4667\n",
      "Accuracy on test data: 0.4833\n"
     ]
    }
   ],
   "source": [
    "# Define range of context window sizes\n",
    "ks = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Initialize lists for storing accuracies and top words\n",
    "accs = list()\n",
    "tops = list()\n",
    "\n",
    "# Loop over context window sizes\n",
    "for k in ks:\n",
    "    \n",
    "    print('Using context window size of {}...'.format(k))\n",
    "\n",
    "    # Convert encoded and padded right and left context into sparse vectors\n",
    "    for data in [train, dev, test]:\n",
    "        data['sparse'] = data.apply(lambda x: sent2sparse(x.enc_1[-k:], x.enc_2[-k:], set(id2w.keys())), axis=1)\n",
    "\n",
    "    # Transform all data to torch tensors\n",
    "    train_x = torch.tensor(list(train['sparse'])).float()\n",
    "    train_y = torch.tensor([p2id[p] for p in train.label])\n",
    "    dev_x = torch.tensor(list(dev['sparse'])).float()\n",
    "    dev_y = torch.tensor([p2id[p] for p in dev.label])\n",
    "    test_x = torch.tensor(list(test['sparse'])).float()\n",
    "    test_y = torch.tensor([p2id[p] for p in test.label])\n",
    "\n",
    "    # Train and evaluate model\n",
    "    classifier = LRClassifier(input_dim, output_dim)\n",
    "    acc, true_lr, pred_lr = train_classifier(classifier, train_x, train_y, dev_x, dev_y, test_x, test_y, device)\n",
    "    \n",
    "    # Store accuracies and top words\n",
    "    accs.append(acc)\n",
    "    tops.append([[id2w[i+2] for i in l] for l in classifier.linear.weight.topk(k=10, dim=-1)[1].tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A) What accuracy would a classifier get that predicts classes based on random guesses? How\n",
    "does the logistic regression classifier compare to that baseline?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we are dealing with 4 classes and balanced data, a classifier based on random guesses would get an accuracy of 25%. The accuracy of the logistic regression classifier is way above that random baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B) Plot the accuracy as a function of the context window size $k$. What do you observe? What conclusions can you draw regarding the linguistic information necessary for predicting particles?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create plot of classification performance as a function of k\n",
    "fig, ax = plt.subplots(1, figsize=(12, 6))\n",
    "\n",
    "ax.plot(ks, accs)\n",
    "ax.set_title('Classification performance as a function of $k$')\n",
    "ax.set_xlabel('$k$')\n",
    "ax.set_ylabel('Classification performance (accuracy)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a direct link between the context window size and the classification performance, with smaller values of $k$ leading to better performance. This suggests that the narrow syntactic context is more predictive of particles than the broader topical context. Notice the parallel to word embedding training, where smaller context window sizes generally lead to embeddings that capture more syntactic information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C) For each $k$, examine the top 10 predictive words of each particle. Are your observations in line with the hypothesis made above?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context window size of 1:\n",
      "Top predictive words for over: ['republicans', 'parkinsons', 'planes', 'unify', '500', '54', 'nearly', 'map', 'crazies', 'threats']\n",
      "Top predictive words for back: ['always', 'seat', 'winning', 'later', 'should', 'good', 'mean', 'building', 'never', 'weekends']\n",
      "Top predictive words for around: ['scandals', 'actually', 'barely', 'bad', 'than', '100000', 'sentiment', 'roads', 'having', 'supporters']\n",
      "Top predictive words for out: ['military', 'carry', 'ill', 'sent', 'crossed', 'looks', 'entirely', 'called', 'word', 'drops']\n",
      "Context window size of 2:\n",
      "Top predictive words for over: ['talking', 'scratch', 'quick', 'twice', 'drugs', 'fired', 'whose', 'hurt', 'talked', 'increase']\n",
      "Top predictive words for back: ['strong', 'machine', '1000', 'overwhelming', 'bit', 'hundreds', 'few', 'says', 'invite', 'falls']\n",
      "Top predictive words for around: ['youll', 'finish', 'criminal', 'tweets', 'head', 'bullshit', 'trying', 'everywhere', 'allegations', 'thank']\n",
      "Top predictive words for out: ['tossing', 'military', 'knock', 'settle', 'student', 'entirely', 'violently', 'lied', 'emails', 'anyways']\n",
      "Context window size of 3:\n",
      "Top predictive words for over: ['run', 'flynn', 'destroyed', 'declare', 'grew', 'trouble', 'start', 'drugs', 'count', 'smooth']\n",
      "Top predictive words for back: ['building', 'argue', 'democracy', 'falls', 'totally', 'candidates', 'hundreds', 'overwhelming', 'senator', 'build']\n",
      "Top predictive words for around: ['student', 'expect', 'whenever', 'order', 'request', 'circle', 'opinion', 'sexually', 'races', 'concentration']\n",
      "Top predictive words for out: ['dinner', 'team', 'area', 'flight', 'looks', 'rented', 'plus', 'apples', 'door', 'board']\n",
      "Context window size of 4:\n",
      "Top predictive words for over: ['drunk', 'mongering', 'peoples', 'blame', 'flynn', 'friends', 'fed', 'ruling', 'grew', 'effectively']\n",
      "Top predictive words for back: ['300', 'building', 'americans', 'child', 'buying', 'tpp', 'yeah', 'ones', 'wearing', 'style']\n",
      "Top predictive words for around: ['also', 'kept', 'sources', 'tied', 'immigration', 'comfort', 'libertarian', 'whenever', 'simple', 'fisa']\n",
      "Top predictive words for out: ['area', 'team', 'weeks', 'industry', 'stop', 'eloquent', 'step', 'profit', 'done', 'met']\n",
      "Context window size of 5:\n",
      "Top predictive words for over: ['though', 'car', 'tomorrow', 'feel', 'equal', 'useful', 'corruption', 'perception', 'forms', 'crush']\n",
      "Top predictive words for back: ['union', 'hey', 'cycles', 'faith', 'tea', 'constant', 'quality', 'background', 'paying', 'confirm']\n",
      "Top predictive words for around: ['develop', 'supports', 'plans', 'save', 'winners', 'taxes', 'spinning', 'finish', 'politics', 'show']\n",
      "Top predictive words for out: ['role', 'oregon', 'released', 'latest', 'tax', 'law', 'companies', 'buying', 'scapegoat', 'allow']\n"
     ]
    }
   ],
   "source": [
    "for k, top in zip(ks, tops):\n",
    "    print('Context window size of {}:'.format(k))\n",
    "    for i in range(4):\n",
    "        print('Top predictive words for {}:'.format(id2p[i]), top[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context window size of 1:\n",
      "Top predictive words for over: ['republicans', 'parkinsons', 'planes', 'unify', '500', '54', 'nearly', 'map', 'crazies', 'threats']\n",
      "Top predictive words for back: ['always', 'seat', 'winning', 'later', 'should', 'good', 'mean', 'building', 'never', 'weekends']\n",
      "Top predictive words for around: ['scandals', 'actually', 'barely', 'bad', 'than', '100000', 'sentiment', 'roads', 'having', 'supporters']\n",
      "Top predictive words for out: ['military', 'carry', 'ill', 'sent', 'crossed', 'looks', 'entirely', 'called', 'word', 'drops']\n",
      "Context window size of 2:\n",
      "Top predictive words for over: ['talking', 'scratch', 'quick', 'twice', 'drugs', 'fired', 'whose', 'hurt', 'talked', 'increase']\n",
      "Top predictive words for back: ['strong', 'machine', '1000', 'overwhelming', 'bit', 'hundreds', 'few', 'says', 'invite', 'falls']\n",
      "Top predictive words for around: ['youll', 'finish', 'criminal', 'tweets', 'head', 'bullshit', 'trying', 'everywhere', 'allegations', 'thank']\n",
      "Top predictive words for out: ['tossing', 'military', 'knock', 'settle', 'student', 'entirely', 'violently', 'lied', 'emails', 'anyways']\n",
      "Context window size of 3:\n",
      "Top predictive words for over: ['run', 'flynn', 'destroyed', 'declare', 'grew', 'trouble', 'start', 'drugs', 'count', 'smooth']\n",
      "Top predictive words for back: ['building', 'argue', 'democracy', 'falls', 'totally', 'candidates', 'hundreds', 'overwhelming', 'senator', 'build']\n",
      "Top predictive words for around: ['student', 'expect', 'whenever', 'order', 'request', 'circle', 'opinion', 'sexually', 'races', 'concentration']\n",
      "Top predictive words for out: ['dinner', 'team', 'area', 'flight', 'looks', 'rented', 'plus', 'apples', 'door', 'board']\n",
      "Context window size of 4:\n",
      "Top predictive words for over: ['drunk', 'mongering', 'peoples', 'blame', 'flynn', 'friends', 'fed', 'ruling', 'grew', 'effectively']\n",
      "Top predictive words for back: ['300', 'building', 'americans', 'child', 'buying', 'tpp', 'yeah', 'ones', 'wearing', 'style']\n",
      "Top predictive words for around: ['also', 'kept', 'sources', 'tied', 'immigration', 'comfort', 'libertarian', 'whenever', 'simple', 'fisa']\n",
      "Top predictive words for out: ['area', 'team', 'weeks', 'industry', 'stop', 'eloquent', 'step', 'profit', 'done', 'met']\n",
      "Context window size of 5:\n",
      "Top predictive words for over: ['though', 'car', 'tomorrow', 'feel', 'equal', 'useful', 'corruption', 'perception', 'forms', 'crush']\n",
      "Top predictive words for back: ['union', 'hey', 'cycles', 'faith', 'tea', 'constant', 'quality', 'background', 'paying', 'confirm']\n",
      "Top predictive words for around: ['develop', 'supports', 'plans', 'save', 'winners', 'taxes', 'spinning', 'finish', 'politics', 'show']\n",
      "Top predictive words for out: ['role', 'oregon', 'released', 'latest', 'tax', 'law', 'companies', 'buying', 'scapegoat', 'allow']\n"
     ]
    }
   ],
   "source": [
    "for k, top in zip(ks, tops):\n",
    "    print('Context window size of {}:'.format(k))\n",
    "    for i in range(4):\n",
    "        print('Top predictive words for {}:'.format(id2p[i]), top[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For smaller values of $k$, several of the most predictive words frequently occur in syntactic contexts with the particle (e.g., _cenetered around_). This is also the case for some larger values of $k$, but arguably to a lesser extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III: Feed-forward Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feed-forward neural network classifier class\n",
    "class FNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        \n",
    "        super(FNNClassifier, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.tanh(self.linear_1(x))\n",
    "        return self.linear_2(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use the '.sparse' accessor with Sparse data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-dba368bd3291>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Transform all data to torch tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp2id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdev_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5454\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5455\u001b[0m         ):\n\u001b[1;32m-> 5456\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5458\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0maccessor_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\sparse\\accessor.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\sparse\\accessor.py\u001b[0m in \u001b[0;36m_validate\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mdtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSparseDtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validation_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use the '.sparse' accessor with Sparse data."
     ]
    }
   ],
   "source": [
    "# Convert encoded and padded right and left context into sparse vectors\n",
    "for data in [train, dev, test]:\n",
    "    data['sparse'] = data.apply(lambda x: sent2sparse(x.enc_1[-1:], x.enc_2[-1:], set(id2w.keys())), axis=1)\n",
    "\n",
    "# Transform all data to torch tensors\n",
    "train_x = torch.tensor(list(train.sparse)).float()\n",
    "train_y = torch.tensor([p2id[p] for p in train.label])\n",
    "dev_x = torch.tensor(list(dev.sparse)).float()\n",
    "dev_y = torch.tensor([p2id[p] for p in dev.label])\n",
    "test_x = torch.tensor(list(test.sparse)).float()\n",
    "test_y = torch.tensor([p2id[p] for p in test.label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "input_dim = 5000\n",
    "output_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range of dimensions\n",
    "ds = [5, 10, 50, 100, 500]\n",
    "\n",
    "# Initialize lists for storing accuracies\n",
    "accs = list()\n",
    "\n",
    "# Loop over dimensions\n",
    "for d in ds:\n",
    "    \n",
    "    print('Using hidden dimension of {:03d}...'.format(d))\n",
    "\n",
    "    # Train and evaluate model\n",
    "    classifier = FNNClassifier(input_dim, output_dim, d)\n",
    "    acc, true_ffn, pred_ffn = train_classifier(classifier, train_x, train_y, dev_x, dev_y, test_x, test_y, device)\n",
    "    \n",
    "    # Store accuracies\n",
    "    accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun with best dimension\n",
    "classifier = FNNClassifier(input_dim, output_dim, 50)\n",
    "acc, true_ffn, pred_ffn = train_classifier(classifier, train_x, train_y, dev_x, dev_y, test_x, test_y, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect cases of wrong logistic regression predictions and correct feed-forward neural network predictions\n",
    "n = 5\n",
    "\n",
    "for s_1, s_2, l, p_lr, p_ffn in zip(test.sent_1, test.sent_2, true_lr, pred_lr, pred_ffn):\n",
    "    if l != p_lr and l == p_ffn:\n",
    "        print(id2p[l], id2p[p_lr], id2p[p_ffn])\n",
    "        print('\\t'.join(s_1[-5:]), '\\t\\t', '\\t'.join(s_2[:5]))\n",
    "        print()\n",
    "        n -= 1\n",
    "\n",
    "    if n == 0:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A) How\n",
    "does this classifier compare to the logistic regression classifier?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tuned $d$, the feed-forward neural network classifier performs better than the logistic regression classifier. For the best value of $d$, the difference amounts to 2%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B) Plot the accuracy as a function of the hidden dimension $d$. What do you observe?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot of classification performance as a function of k\n",
    "fig, ax = plt.subplots(1, figsize=(12, 6))\n",
    "\n",
    "ax.plot(ds, accs)\n",
    "ax.set_title('Classification performance as a function of $d$')\n",
    "ax.set_xlabel('$d$')\n",
    "ax.set_ylabel('Classification performance (accuracy)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performance is reached with $d = 50$. For smaller values, the performance of the feed-forward neural network classifier is similar or worse than the logistic regression classifier. For larger values, the performance does not improve further and is a bit worse than at the peak value. When repeating the hyperparameter search multiple times, $d = 100$ sometimes performs better than $d = 50$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part IV: LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM classifier class\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \n",
    "    # Pass hyperparameters as arguments\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout, context):\n",
    "        \n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        \n",
    "        self.context = context\n",
    "        \n",
    "        if self.context in {'left', 'both'}:\n",
    "        \n",
    "            # Define embedding and LSTM layers for left context (batch_dim x 5 -> batch x 5 x embedding_dim -> batch_dim x hidden_dim)\n",
    "            self.embedding_1 = nn.Embedding(input_dim, embedding_dim, padding_idx=0)\n",
    "            self.lstm_1 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "            \n",
    "        if self.context in {'right', 'both'}:\n",
    "            \n",
    "            # Define embedding and LSTM layers for right context (batch_dim x 5 -> batch x 5 x embedding_dim -> batch_dim x hidden_dim)\n",
    "            self.embedding_2 = nn.Embedding(input_dim, embedding_dim, padding_idx=0)\n",
    "            self.lstm_2 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "            \n",
    "        if self.context in {'left', 'right'}:\n",
    "        \n",
    "            # Define dense layer (batch_dim x hidden_dim -> batch_dim x output_dim)\n",
    "            self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "            \n",
    "        if self.context == 'both':\n",
    "            \n",
    "            # Define dense layer (batch_dim x 2 * hidden_dim -> batch_dim x output_dim)\n",
    "            self.linear = nn.Linear(2 * hidden_dim, output_dim)\n",
    "        \n",
    "        # Define dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        sent_1, sent_2 = torch.chunk(x, 2, dim=-1)\n",
    "        \n",
    "        if self.context in {'left', 'both'}:\n",
    "            \n",
    "            # Define flow through embedding and LSTM layers for left context\n",
    "            emb_1 = self.dropout(self.embedding_1(sent_1))\n",
    "            output_1, (hidden_1, cell_1) = self.lstm_1(emb_1)\n",
    "            \n",
    "        if self.context in {'right', 'both'}:\n",
    "            \n",
    "            # Define flow through embedding and LSTM layers for right context            \n",
    "            emb_2 = self.dropout(self.embedding_2(sent_2))            \n",
    "            output_2, (hidden_2, cell_2) = self.lstm_2(emb_2)\n",
    "            \n",
    "        if self.context == 'left':\n",
    "            \n",
    "            # Pass through dense layer\n",
    "            output = self.linear(self.dropout(output_1[:, -1, :]))\n",
    "            \n",
    "        if self.context == 'right':\n",
    "            \n",
    "            # Pass through dense layer\n",
    "            output = self.linear(self.dropout(output_2[:, -1, :]))\n",
    "            \n",
    "        if self.context == 'both':\n",
    "        \n",
    "            # Concatenate and pass through dense layer\n",
    "            output = self.linear(self.dropout(torch.cat((output_1[:, -1, :], output_2[:, -1, :]), dim=-1)))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all data to torch tensors\n",
    "train_x = torch.cat((torch.tensor(list(train.enc_1)), torch.tensor(list(train.enc_2))), dim=-1) \n",
    "train_y = torch.tensor([p2id[p] for p in train.label])\n",
    "dev_x = torch.cat((torch.tensor(list(dev.enc_1)), torch.tensor(list(dev.enc_2))), dim=-1)\n",
    "dev_y = torch.tensor([p2id[p] for p in dev.label])\n",
    "test_x = torch.cat((torch.tensor(list(test.enc_1)), torch.tensor(list(test.enc_2))), dim=-1)\n",
    "test_y = torch.tensor([p2id[p] for p in test.label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_1</th>\n",
       "      <th>sent_2</th>\n",
       "      <th>label</th>\n",
       "      <th>enc_1</th>\n",
       "      <th>enc_2</th>\n",
       "      <th>sparse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>[sandy, had]</td>\n",
       "      <td>[100b, in, funding, and, it, affected, way, mo...</td>\n",
       "      <td>around</td>\n",
       "      <td>[0, 0, 0, 3031, 80]</td>\n",
       "      <td>[11, 4, 1051, 8, 5248]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>[so, once, shes, there, theres, no, reason, to...</td>\n",
       "      <td>[even, if, you, buy, into, the, fallacy, that,...</td>\n",
       "      <td>around</td>\n",
       "      <td>[62, 276, 3, 203, 11]</td>\n",
       "      <td>[91, 465, 13, 22, 72]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>[as, a, result, they, gained, extraterritorial...</td>\n",
       "      <td>[the, world]</td>\n",
       "      <td>around</td>\n",
       "      <td>[745, 371, 3920, 8, 2504]</td>\n",
       "      <td>[0, 0, 0, 131, 2]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>[theyre, the, ones, paying, all, these, politi...</td>\n",
       "      <td>[so, they, can, price, gouge, necessities, for...</td>\n",
       "      <td>over</td>\n",
       "      <td>[153, 516, 3, 263, 74]</td>\n",
       "      <td>[9339, 1625, 50, 14, 32]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>[payment, for, class, a, drugs, , 1mhowever, w...</td>\n",
       "      <td>[]</td>\n",
       "      <td>out</td>\n",
       "      <td>[870, 39, 10, 2508, 27]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>[the, fact, that, a, contested, convention, is...</td>\n",
       "      <td>[on, the, first, ballot]</td>\n",
       "      <td>over</td>\n",
       "      <td>[9, 39, 5, 1091, 158]</td>\n",
       "      <td>[0, 2607, 172, 2, 16]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>[the, last, two, gop, presidential, nominees, ...</td>\n",
       "      <td>[to, the, center, in, time, for, the, national...</td>\n",
       "      <td>back</td>\n",
       "      <td>[900, 3, 87, 7, 213]</td>\n",
       "      <td>[61, 8, 1514, 2, 3]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>[im, not, old, by, any, terms, but, i, swear, ...</td>\n",
       "      <td>[curled, up, in, a, ball, unable, to, stop, co...</td>\n",
       "      <td>out</td>\n",
       "      <td>[67, 3, 3783, 47, 67]</td>\n",
       "      <td>[2355, 5, 8, 47, 12852]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>[a, few, of, the, women]</td>\n",
       "      <td>[my, campus, who, are, muslim, have, told, me,...</td>\n",
       "      <td>around</td>\n",
       "      <td>[5, 169, 6, 2, 359]</td>\n",
       "      <td>[861, 21, 46, 12853, 53]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>[if, the, latter, i, cant, really, feel, bad, ...</td>\n",
       "      <td>[450kyr]</td>\n",
       "      <td>around</td>\n",
       "      <td>[12, 152, 46, 9, 201]</td>\n",
       "      <td>[0, 0, 0, 0, 12854]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sent_1  \\\n",
       "1118                                       [sandy, had]   \n",
       "852   [so, once, shes, there, theres, no, reason, to...   \n",
       "1431  [as, a, result, they, gained, extraterritorial...   \n",
       "4981  [theyre, the, ones, paying, all, these, politi...   \n",
       "3221  [payment, for, class, a, drugs, , 1mhowever, w...   \n",
       "...                                                 ...   \n",
       "5757  [the, fact, that, a, contested, convention, is...   \n",
       "2982  [the, last, two, gop, presidential, nominees, ...   \n",
       "3808  [im, not, old, by, any, terms, but, i, swear, ...   \n",
       "1447                           [a, few, of, the, women]   \n",
       "662   [if, the, latter, i, cant, really, feel, bad, ...   \n",
       "\n",
       "                                                 sent_2   label  \\\n",
       "1118  [100b, in, funding, and, it, affected, way, mo...  around   \n",
       "852   [even, if, you, buy, into, the, fallacy, that,...  around   \n",
       "1431                                       [the, world]  around   \n",
       "4981  [so, they, can, price, gouge, necessities, for...    over   \n",
       "3221                                                 []     out   \n",
       "...                                                 ...     ...   \n",
       "5757                           [on, the, first, ballot]    over   \n",
       "2982  [to, the, center, in, time, for, the, national...    back   \n",
       "3808  [curled, up, in, a, ball, unable, to, stop, co...     out   \n",
       "1447  [my, campus, who, are, muslim, have, told, me,...  around   \n",
       "662                                            [450kyr]  around   \n",
       "\n",
       "                          enc_1                     enc_2  \\\n",
       "1118        [0, 0, 0, 3031, 80]    [11, 4, 1051, 8, 5248]   \n",
       "852       [62, 276, 3, 203, 11]     [91, 465, 13, 22, 72]   \n",
       "1431  [745, 371, 3920, 8, 2504]         [0, 0, 0, 131, 2]   \n",
       "4981     [153, 516, 3, 263, 74]  [9339, 1625, 50, 14, 32]   \n",
       "3221    [870, 39, 10, 2508, 27]           [0, 0, 0, 0, 0]   \n",
       "...                         ...                       ...   \n",
       "5757      [9, 39, 5, 1091, 158]     [0, 2607, 172, 2, 16]   \n",
       "2982       [900, 3, 87, 7, 213]       [61, 8, 1514, 2, 3]   \n",
       "3808      [67, 3, 3783, 47, 67]   [2355, 5, 8, 47, 12852]   \n",
       "1447        [5, 169, 6, 2, 359]  [861, 21, 46, 12853, 53]   \n",
       "662       [12, 152, 46, 9, 201]       [0, 0, 0, 0, 12854]   \n",
       "\n",
       "                                                 sparse  \n",
       "1118  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "852   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "1431  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4981  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3221  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "5757  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "2982  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3808  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1447  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "662   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[4800 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "input_dim = len(w2id) + 2\n",
    "embedding_dim = 300\n",
    "hidden_dim = 200\n",
    "output_dim = 4\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test on both contexts\n",
    "classifier = LSTMClassifier(input_dim, embedding_dim, hidden_dim, output_dim, dropout, 'both')\n",
    "acc, true_b, pred_b = train_classifier(classifier, train_x, train_y, dev_x, dev_y, test_x, test_y, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect cases of wrong feed-forward neural network predictions and correct LSTM predictions\n",
    "n = 5\n",
    "\n",
    "for s_1, s_2, l, p_ffn, p_lstm in zip(test.sent_1, test.sent_2, true_ffn, pred_ffn, pred_b):\n",
    "    if l != p_ffn and l == p_lstm:\n",
    "        print(id2p[l], id2p[p_ffn], id2p[p_lstm])\n",
    "        print('\\t'.join(s_1[-5:]), '\\t\\t', '\\t'.join(s_2[:5]))\n",
    "        print()\n",
    "        n -= 1\n",
    "\n",
    "    if n == 0:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A) How\n",
    "does the LSTM classifier compare to the feed-forward neural network classifier?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM outperforms the feed-forward neural network classifier substantially, leading to a performance improvement of 8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B)  Modify the LSTM architecture so that it only takes the left or right context into account. Train and test these two models. Which of the two contexts provides more information for\n",
    "particle prediction?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test on left contexts\n",
    "classifier = LSTMClassifier(input_dim, embedding_dim, hidden_dim, output_dim, dropout, 'left')\n",
    "acc, true_l, pred_l = train_classifier(classifier, train_x, train_y, dev_x, dev_y, test_x, test_y, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test on right contexts\n",
    "classifier = LSTMClassifier(input_dim, embedding_dim, hidden_dim, output_dim, dropout, 'right')\n",
    "acc, true_r, pred_r = train_classifier(classifier, train_x, train_y, dev_x, dev_y, test_x, test_y, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models perform worse than the particle classifier trained on both contexts. The model trained on the right context performs substantially better than the one trained on the left context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C) Tabulate the number of misclassified examples as a function of the number of UNK tokens\n",
    "in the left and right contexts. Manually inspect a couple of misclassified examples. What do\n",
    "you observe? How do your observations relate to results of earlier parts of the formative?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_counter = defaultdict(Counter)\n",
    "\n",
    "for c_l, c_r, l, p in zip(test.enc_1, test.enc_2, true_b, pred_b):\n",
    "    unk_counter[len([i for i in c_l if i == 1])]['left_f'] += int(l != p)\n",
    "    unk_counter[len([i for i in c_r if i == 1])]['right_f'] += int(l != p)\n",
    "    unk_counter[len([i for i in c_l if i == 1])]['left_c'] += int(l == p)\n",
    "    unk_counter[len([i for i in c_r if i == 1])]['right_c'] += int(l == p)\n",
    "    \n",
    "for n in unk_counter:\n",
    "    total = sum(unk_counter[n].values())\n",
    "    unk_counter[n] = {t: unk_counter[n][t] / total for t in unk_counter[n]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.bar([x - 0.3 for x in range(3)], [unk_counter[n]['left_c'] for n in range(3)], 0.2, label='Left context correct')\n",
    "ax.bar([x - 0.1 for x in range(3)], [unk_counter[n]['left_f'] for n in range(3)], 0.2, label='Left context false')\n",
    "ax.bar([x + 0.1 for x in range(3)], [unk_counter[n]['right_c'] for n in range(3)], 0.2, label='Right context correct')\n",
    "ax.bar([x + 0.3 for x in range(3)], [unk_counter[n]['right_f'] for n in range(3)], 0.2, label='Right context false')\n",
    "\n",
    "ax.xaxis.set_ticks([0, 1, 2, 3])\n",
    "ax.set_xlabel('Number of UNK tokens')\n",
    "ax.set_ylabel('Share of examples')\n",
    "ax.set_title('Examples by number of UNK tokens and context type')\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print five misclassified examples with two UNK tokens\n",
    "n = 5\n",
    "\n",
    "for s_1, s_2, c_l, c_r, l, p in zip(test.sent_1, test.sent_2, test.enc_1, test.enc_2, true_b, pred_b):\n",
    "    if (len([i for i in c_l if i == 1]) == 2 or len([i for i in c_r if i == 1]) == 2) and l != p:\n",
    "        print(id2p[l], id2p[p])\n",
    "        print('\\t'.join(s_1[-5:]), '\\t\\t', '\\t'.join(s_2[:5]))\n",
    "        print('\\t'.join([str(t) for t in c_l]), '\\t\\t', '\\t'.join([str(t) for t in c_r][::-1]))\n",
    "        print()\n",
    "        n -= 1\n",
    "\n",
    "    if n == 0:\n",
    "        break      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of UNK tokens has a negative influence on the model performance. The effect is more pronounced for the right context. In addition, it is interesting to note that most of the UNK tokens occurred close to the particle. This is in line with the observation made above that the nearest words are most predictive of the particle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D) Create a confusion matrix of the predicted labels versus the true labels. What do you\n",
    "observe?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for labels, preds in [(true_b, pred_b), (true_l, pred_l), (true_r, pred_r)]:\n",
    "    \n",
    "    # Initialize confuction matrix\n",
    "    c_matrix = defaultdict(Counter)\n",
    "\n",
    "    # Create confusion matrix\n",
    "    for l, p in zip(labels, preds):\n",
    "        c_matrix[id2p[l]][id2p[p]] += 1\n",
    "\n",
    "    # Display confusion matrix\n",
    "    print(pd.DataFrame.from_dict(c_matrix, orient='index', columns=list(p2id.keys())).reindex(index=list(p2id.keys())))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all three models, most misclassifications occurred for _around_. Also, all three models have a relatively low number of errors for _back_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part V: Overall Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the three models to the trigram model presented in class. What information is available for the classifier in each of the four approaches? Are you able to interpret the overall\n",
    "success of the models in relation to the information that is available in each one and the ability\n",
    "to exploit it in an optimal fashion?**\n",
    "\n",
    "The performance of the logistic regression classifier is similar to the trigram model presented in class. For a fair comparison, we need to look at the model using a window size of two, which is only slightly better than the trigram model. The feed-forward neural network is already substantially better than the trigram model. It has a much larger model capacity, i.e., much more trainable parameters, than the trigram model, which allows it to capture the patterns in the data with a greater detail. As opposed to the logistic regression and the feed-forward neural network classfiers, the LSTM has information about the order of words, which is crucial for the task of particle prediction and hence leads to a large performance increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
